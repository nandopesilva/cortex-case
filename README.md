# Pipeline de An√°lise Demogr√°fica do Brasil com Dados IBGE üó∫Ô∏èüìä

Este projeto implementa um pipeline de an√°lise demogr√°fica do Brasil utilizando dados do IBGE, integrando ferramentas como Apache Airflow, Pandas e PostgreSQL. O pipeline coleta, transforma e carrega informa√ß√µes de √°rea territorial e popula√ß√£o para fornecer insights ricos sobre densidade populacional e distribui√ß√£o demogr√°fica.

## üõ†Ô∏è Estrutura do Projeto

### Arquivos e Diret√≥rios
- **`dags/`**: Cont√©m a DAG principal do Airflow e os scripts de ETL.
  - **`ibge.py`**: Define o pipeline no Apache Airflow.
  - **`data/`**: Cont√©m os arquivos de entrada:
    - `AR_BR_RG_UF_RGINT_MES_MIC_MUN_2022.xls`: Dados de √°rea territorial.
    - `tabela6579.xlsx`: Dados populacionais.
  - **`outputs/`**: Diret√≥rio para os arquivos processados.
  - **`scripts/`**: Scripts para as etapas do pipeline.
    - **`extract.py`**: Coleta dos dados brutos.
    - **`transform.py`**: Transforma√ß√£o dos dados.
    - **`load.py`**: Salva os resultados em CSV e carrega no banco de dados.
- **`docker-compose.yml`**: Configura√ß√£o para executar o Airflow e PostgreSQL com Docker.
- **`requirements.txt`**: Depend√™ncias do projeto.

#### Fontes de Dados

- [√Årea](https://geoftp.ibge.gov.br/organizacao_do_territorio/estrutura_territorial/areas_territoriais/2022/AR_BR_RG_UF_RGINT_MES_MIC_MUN_2022.xls)
- [Popula√ß√£o](https://sidra.ibge.gov.br/tabela/6579)

### Fluxo do Pipeline

O pipeline √© composto pelas seguintes tarefas, definidas na DAG `ibge`:

1. **`extract_area`**: Extrai dados de √°rea territorial.
2. **`extract_population`**: Extrai dados populacionais.
3. **`transform`**: Combina e processa os dados extra√≠dos.
4. **`load`**: Salva os dados processados em um arquivo CSV e no banco de dados PostgreSQL.

## üöÄ Configura√ß√£o e Execu√ß√£o

### Pr√©-requisitos
- Docker
- Docker Compose
- Python 3.8+

### Passos para Execu√ß√£o

1. Clone este reposit√≥rio:

   ```bash
   git clone https://github.com/nandopesilva/cortex-case
   ```
   
2. Inicie os servi√ßos com Docker Compose:

    ```bash
    docker-compose --project-name case up -d 
    ```

3. Acesse a interface do Airflow em [http://localhost:8080](http://localhost:8080) com as credenciais:

- **Usu√°rio:** admin
- **Senha:** admin

4. Configure a conex√£o do Airflow com o banco de dados PostgreSQL:

- **Connection:** postgres_default
- **Host:** host.docker.internal 
- **Database:** cortex 
- **Login:** cortex 
- **Password:** cortex 
- **Port:** 5432

![Connections](./docs/images/image1.jpeg)

5. Executando a DAG:

![Execu√ß√£o](./docs/images/image2.png)

6. üßë‚Äçüíª Tecnologias Utilizadas

- **Apache Airflow:** Orquestra√ß√£o do pipeline.
- **Docker:** Ambiente de desenvolvimento isolado.
- **Pandas:** Manipula√ß√£o e transforma√ß√£o de dados.
- **PostgreSQL:** Armazenamento dos resultados.
