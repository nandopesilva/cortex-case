# Pipeline de An√°lise Demogr√°fica do Brasil com Dados IBGE üó∫Ô∏èüìä

Este projeto implementa um pipeline de an√°lise demogr√°fica do Brasil utilizando dados do IBGE, integrando ferramentas como Apache Airflow, pandas, e PostgreSQL. O pipeline coleta, transforma e carrega informa√ß√µes de √°rea territorial e popula√ß√£o para fornecer insights ricos sobre densidade populacional e distribui√ß√£o demogr√°fica.

## üõ†Ô∏è Estrutura do Projeto

### Arquivos e Diret√≥rios
- **`dags/`**: Cont√©m a DAG principal do Airflow e os scripts de ETL.
  - **`ibge.py`**: Define o pipeline no Apache Airflow.
  - **`scripts/`**: Scripts para as etapas do pipeline:
    - **`extract.py`**: Coleta e valida os dados brutos.
    - **`transform.py`**: Realiza transforma√ß√µes e integra os dados.
    - **`load.py`**: Salva os resultados em CSV e carrega no banco de dados.
- **`data/`**: Cont√©m os arquivos de entrada:
  - `AR_BR_RG_UF_RGINT_MES_MIC_MUN_2022.xls`: Dados de √°rea territorial.
  - `tabela6579.xlsx`: Dados populacionais.
- **`outputs/`**: Diret√≥rio para os arquivos processados.
- **`docker-compose.yml`**: Configura√ß√£o para executar o Airflow e PostgreSQL com Docker.
- **`requirements.txt`**: Depend√™ncias do projeto.

Obs.: Os dados pupulacionais foram extra√≠dos do link https://sidra.ibge.gov.br/tabela/6579 e os dados de √°rea foram
      extra√≠dos do link https://geoftp.ibge.gov.br/organizacao_do_territorio/estrutura_territorial/areas_territoriais/2022/AR_BR_RG_UF_RGINT_MES_MIC_MUN_2022.xls

### Fluxo do Pipeline

O pipeline √© composto pelas seguintes tarefas, definidas na DAG `ibge`:
1. **`extract_area`**: Extrai dados de √°rea territorial.
2. **`extract_population`**: Extrai dados populacionais.
3. **`transform`**: Combina e processa os dados extra√≠dos.
4. **`load`**: Salva os dados processados em um arquivo CSV e no banco de dados PostgreSQL.

## üöÄ Configura√ß√£o e Execu√ß√£o

### Pr√©-requisitos
- **Docker** e **Docker Compose** instalados.
- **Python 3.8+** (opcional, para executar localmente).

### Passos para Execu√ß√£o

1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/nandopesilva/cortex-case
   
2. Inicie os servi√ßos com Docker Compose:

- docker-compose --project-name case up -d 

3. Acesse a interface do Airflow em http://localhost:8080 com as credenciais:

- Usu√°rio: admin
- Senha: admin

4. üßë‚Äçüíª Tecnologias Utilizadas

- Apache Airflow: Orquestra√ß√£o do pipeline.
- pandas: Manipula√ß√£o e transforma√ß√£o de dados.
- PostgreSQL: Armazenamento dos resultados.
- Docker: Ambiente de desenvolvimento isolado.